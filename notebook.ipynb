{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raneem-Ali0/Give-Life-Predict-Blood-Donations/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "3"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "8sTlUJBW-zH-"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Inspecting transfusion.data file\n",
        "<p><img src=\"https://assets.datacamp.com/production/project_646/img/blood_donation.png\" style=\"float: right;\" alt=\"A pictogram of a blood bag with blood donation written in it\" width=\"200\"></p>\n",
        "<p>Blood transfusion saves lives - from replacing lost blood during major surgery or a serious injury to treating various illnesses and blood disorders. Ensuring that there's enough blood in supply whenever needed is a serious challenge for the health professionals. According to <a href=\"https://www.webmd.com/a-to-z-guides/blood-transfusion-what-to-know#1\">WebMD</a>, \"about 5 million Americans need a blood transfusion every year\".</p>\n",
        "<p>Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive. We want to predict whether or not a donor will give blood the next time the vehicle comes to campus.</p>\n",
        "<p>The data is stored in <code>datasets/transfusion.data</code> and it is structured according to RFMTC marketing model (a variation of RFM). We'll explore what that means later in this notebook. First, let's inspect the data.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "3"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "SFtJPORc-zIE",
        "outputId": "828f3640-4617-42e6-b91c-1bf0c95a43f4"
      },
      "cell_type": "code",
      "source": [
        "# Print out the first 5 lines from the transfusion.data file\n",
        "!head -n5 datasets/transfusion.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Recency (months),Frequency (times),Monetary (c.c. blood),Time (months),\"whether he/she donated blood in March 2007\"\r\r\n2 ,50,12500,98 ,1\r\r\n0 ,13,3250,28 ,1\r\r\n1 ,16,4000,35 ,1\r\r\n2 ,20,5000,45 ,1\r\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "3"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "gsKQN-X2-zIG",
        "outputId": "c4ba8efc-be48-48d1-8f08-7f0f797e7996"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "last_input = In[-2]\n",
        "\n",
        "import re\n",
        "try:\n",
        "    bash_cmd = re.search(r'get_ipython\\(\\).system\\(\\'(.*)\\'\\)', last_input).group(1)\n",
        "except AttributeError:\n",
        "    bash_cmd = ''\n",
        "\n",
        "def test_head_command():\n",
        "    assert 'head' in bash_cmd, \\\n",
        "        \"Did you use 'head' command?\"\n",
        "    assert ('-n' in bash_cmd) or ('-5' in bash_cmd), \\\n",
        "        \"Did you use '-n' parameter?\"\n",
        "    assert '5' in bash_cmd, \\\n",
        "        \"Did you specify the correct number of lines to print?\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 1, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_head_command\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 98,
          "data": {
            "text/plain": "1/1 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "10"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "GgMX9qzQ-zIH"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Loading the blood donations data\n",
        "<p>We now know that we are working with a typical CSV file (i.e., the delimiter is <code>,</code>, etc.). We proceed to loading the data into memory.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "10"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "Nd4NQorp-zIH",
        "outputId": "f6e25e26-553b-4b82-d53b-62da4475000c"
      },
      "cell_type": "code",
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Read in dataset\n",
        "transfusion = pd.read_csv('datasets/transfusion.data')\n",
        "\n",
        "# Print out the first rows of our dataset\n",
        "transfusion.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 99,
          "data": {
            "text/plain": "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n0                 2                 50                  12500             98   \n1                 0                 13                   3250             28   \n2                 1                 16                   4000             35   \n3                 2                 20                   5000             45   \n4                 1                 24                   6000             77   \n\n   whether he/she donated blood in March 2007  \n0                                           1  \n1                                           1  \n2                                           1  \n3                                           1  \n4                                           0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Recency (months)</th>\n      <th>Frequency (times)</th>\n      <th>Monetary (c.c. blood)</th>\n      <th>Time (months)</th>\n      <th>whether he/she donated blood in March 2007</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>50</td>\n      <td>12500</td>\n      <td>98</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>13</td>\n      <td>3250</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>16</td>\n      <td>4000</td>\n      <td>35</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>20</td>\n      <td>5000</td>\n      <td>45</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>24</td>\n      <td>6000</td>\n      <td>77</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "10"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "hyU70qED-zII",
        "outputId": "890a8ce6-dc3d-408d-c2fb-c27482ebc1dd"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "last_output = _\n",
        "\n",
        "def test_pandas_loaded():\n",
        "    assert 'pd' in globals(), \\\n",
        "        \"'pd' module not found. Please check your import statement.\"\n",
        "\n",
        "def test_transfusion_loaded():\n",
        "    correct_transfusion = pd.read_csv(\"datasets/transfusion.data\")\n",
        "    assert correct_transfusion.equals(transfusion), \\\n",
        "        \"transfusion not loaded correctly.\"\n",
        "    \n",
        "def test_head_output():\n",
        "    try:\n",
        "        assert \"6000\" in last_output.to_string()\n",
        "    except AttributeError:\n",
        "        assert False, \\\n",
        "            \"Please use transfusion.head() as the last line of code in the cell to inspect the data, not the display() or print() functions.\"\n",
        "    except AssertionError:\n",
        "        assert False, \\\n",
        "            \"Hmm, the output of the cell is not what we expected. You should see 6000 in the first five rows of the transfusion DataFrame.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 3, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_pandas_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_transfusion_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_head_output\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 100,
          "data": {
            "text/plain": "3/3 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "17"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "S_3U7Ndb-zIJ"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Inspecting transfusion DataFrame\n",
        "<p>Let's briefly return to our discussion of RFM model. RFM stands for Recency, Frequency and Monetary Value and it is commonly used in marketing for identifying your best customers. In our case, our customers are blood donors.</p>\n",
        "<p>RFMTC is a variation of the RFM model. Below is a description of what each column means in our dataset:</p>\n",
        "<ul>\n",
        "<li>R (Recency - months since the last donation)</li>\n",
        "<li>F (Frequency - total number of donation)</li>\n",
        "<li>M (Monetary - total blood donated in c.c.)</li>\n",
        "<li>T (Time - months since the first donation)</li>\n",
        "<li>a binary variable representing whether he/she donated blood in March 2007 (1 stands for donating blood; 0 stands for not donating blood)</li>\n",
        "</ul>\n",
        "<p>It looks like every column in our DataFrame has the numeric type, which is exactly what we want when building a machine learning model. Let's verify our hypothesis.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "17"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "XjOgDRP_-zIK",
        "outputId": "449efa55-7caa-44e4-9b6d-dd6ed7e6e377"
      },
      "cell_type": "code",
      "source": [
        "# Print a concise summary of transfusion DataFrame\n",
        "transfusion.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 748 entries, 0 to 747\nData columns (total 5 columns):\nRecency (months)                              748 non-null int64\nFrequency (times)                             748 non-null int64\nMonetary (c.c. blood)                         748 non-null int64\nTime (months)                                 748 non-null int64\nwhether he/she donated blood in March 2007    748 non-null int64\ndtypes: int64(5)\nmemory usage: 29.3 KB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "17"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "W0-HuRuG-zIL",
        "outputId": "9ffd6f39-8111-44b6-e284-575d65d6ca49"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "def strip_comment_lines(cell_input):\n",
        "    \"\"\"Returns cell input string with comment lines removed.\"\"\"\n",
        "    return '\\n'.join(line for line in cell_input.splitlines() if not line.startswith('#'))\n",
        "\n",
        "last_input = strip_comment_lines(In[-2])\n",
        "\n",
        "def test_info_command():\n",
        "    assert 'transfusion' in last_input, \\\n",
        "        \"Expected transfusion variable in your input.\"\n",
        "    assert 'info' in last_input, \\\n",
        "        \"Did you use the correct method?\"\n",
        "    assert 'print' not in last_input, \\\n",
        "        \"Please use transfusion.info() to inspect DataFrame's structure, not the display() or print() functions.\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 1, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_info_command\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 102,
          "data": {
            "text/plain": "1/1 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "24"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "lwMhMhpG-zIM"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Creating target column\n",
        "<p>We are aiming to predict the value in <code>whether he/she donated blood in March 2007</code> column. Let's rename this it to <code>target</code> so that it's more convenient to work with.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "24"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "rsovrwxj-zIN",
        "outputId": "ea7ed71c-daeb-443b-e89b-bf596e851af4"
      },
      "cell_type": "code",
      "source": [
        "# Rename target column as 'target' for brevity \n",
        "transfusion.rename(\n",
        "    columns={'whether he/she donated blood in March 2007': 'target'},\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "# Print out the first 2 rows\n",
        "\n",
        "transfusion.head(2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 103,
          "data": {
            "text/plain": "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n0                 2                 50                  12500             98   \n1                 0                 13                   3250             28   \n\n   target  \n0       1  \n1       1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Recency (months)</th>\n      <th>Frequency (times)</th>\n      <th>Monetary (c.c. blood)</th>\n      <th>Time (months)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>50</td>\n      <td>12500</td>\n      <td>98</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>13</td>\n      <td>3250</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "24"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "YKO9NYv5-zIN",
        "outputId": "be9bed83-145e-406b-b38f-84465d31443e"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "last_output = _\n",
        "\n",
        "def test_target_column_added():\n",
        "    assert 'target' in transfusion.columns, \\\n",
        "        \"'target' column not found in transfusion.columns\"\n",
        "\n",
        "def test_head_2_rows_only():\n",
        "    try:\n",
        "        assert last_output.shape[0] == 2\n",
        "    except AttributeError:\n",
        "        assert False, \\\n",
        "            \"Please use transfusion.head(2) as the last line of code in the cell to inspect the data, not the display() or print() functions.\"\n",
        "    except AssertionError:\n",
        "        assert False, \\\n",
        "            \"Did you call 'head()' method with the correct number of lines?\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 2, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_target_column_added\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_head_2_rows_only\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 104,
          "data": {
            "text/plain": "2/2 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "31"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "OlZdd2Jv-zIO"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Checking target incidence\n",
        "<p>We want to predict whether or not the same donor will give blood the next time the vehicle comes to campus. The model for this is a binary classifier, meaning that there are only 2 possible outcomes:</p>\n",
        "<ul>\n",
        "<li><code>0</code> - the donor will not give blood</li>\n",
        "<li><code>1</code> - the donor will give blood</li>\n",
        "</ul>\n",
        "<p>Target incidence is defined as the number of cases of each individual target value in a dataset. That is, how many 0s in the target column compared to how many 1s? Target incidence gives us an idea of how balanced (or imbalanced) is our dataset.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "31"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "LHKVr2UT-zIO",
        "outputId": "6f0f49d5-7eb0-4a77-edc6-62ad28f97ad5"
      },
      "cell_type": "code",
      "source": [
        "# Print target incidence proportions, rounding output to 3 decimal places\n",
        "transfusion.target.value_counts(normalize=True).round(3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 105,
          "data": {
            "text/plain": "0    0.762\n1    0.238\nName: target, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "31"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "ZxjfDWu0-zIP",
        "outputId": "57d57b1b-33fb-4bb3-fdd4-e9fef72e2412"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "def strip_comment_lines(cell_input):\n",
        "    \"\"\"Returns cell input string with comment lines removed.\"\"\"\n",
        "    return '\\n'.join(line for line in cell_input.splitlines() if not line.startswith('#'))\n",
        "\n",
        "last_input = strip_comment_lines(In[-2])\n",
        "last_output = _\n",
        "\n",
        "def test_command_syntax():\n",
        "    assert 'target' in last_input and (\n",
        "        ('transfusion.' in last_input) or ('transfusion[' in last_input)\n",
        "    ), \\\n",
        "        \"Did you call 'value_counts()' method on 'transfusion.target' column?\"\n",
        "    assert ('value_counts' in last_input) and ('normalize' in last_input), \\\n",
        "        \"Did you use 'normalize=True' parameter?\"\n",
        "    assert 'round' in last_input, \\\n",
        "        \"Did you call 'round()' method?\"\n",
        "    assert 'round(3)' in last_input, \\\n",
        "        \"Did you call 'round()' method with the correct argument?\"\n",
        "    assert last_input.find('value') < last_input.find('round'), \\\n",
        "        \"Did you chain 'value_counts()' and 'round()' methods in the correct order?\"\n",
        "\n",
        "def test_command_output():\n",
        "    try:\n",
        "        assert \"0.762\" in last_output.to_string()\n",
        "    except AttributeError:\n",
        "        assert False, \\\n",
        "            \"Please use transfusion.target.value_counts(normalize=True).round(3) to inspect proportions, not the display() or print() functions.\"\n",
        "    except AssertionError:\n",
        "        assert False, \\\n",
        "            \"Hmm, the output of the cell is not what we expected. You should see 0.762 in your output.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 2, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_command_syntax\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_command_output\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 106,
          "data": {
            "text/plain": "2/2 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "38"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "pVpufW_9-zIP"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Splitting transfusion into train and test datasets\n",
        "<p>We'll now use <code>train_test_split()</code> method to split <code>transfusion</code> DataFrame.</p>\n",
        "<p>Target incidence informed us that in our dataset <code>0</code>s appear 76% of the time. We want to keep the same structure in train and test datasets, i.e., both datasets must have 0 target incidence of 76%. This is very easy to do using the <code>train_test_split()</code> method from the <code>scikit learn</code> library - all we need to do is specify the <code>stratify</code> parameter. In our case, we'll stratify on the <code>target</code> column.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "38"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "mxI69RlE-zIQ",
        "outputId": "c74e7d62-23c4-4613-9885-e7cc4f3c3c9d"
      },
      "cell_type": "code",
      "source": [
        "# Import train_test_split method\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split transfusion DataFrame into\n",
        "# X_train, X_test, y_train and y_test datasets,\n",
        "# stratifying on the `target` column\n",
        "X_train ,X_test ,y_train , y_test  = train_test_split(\n",
        "    transfusion.drop(columns='target'),\n",
        "    transfusion.target,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify= transfusion.target\n",
        ")\n",
        "\n",
        "# Print out the first 2 rows of X_train\n",
        "X_train.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 107,
          "data": {
            "text/plain": "     Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)\n334                16                  2                    500             16\n99                  5                  7                   1750             26",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Recency (months)</th>\n      <th>Frequency (times)</th>\n      <th>Monetary (c.c. blood)</th>\n      <th>Time (months)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>334</th>\n      <td>16</td>\n      <td>2</td>\n      <td>500</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>5</td>\n      <td>7</td>\n      <td>1750</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "38"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "7sUnkAp1-zIQ",
        "outputId": "41306001-978e-41d8-e12d-643a0aa806d2"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "last_output = _\n",
        "\n",
        "def test_train_test_split_loaded():\n",
        "    assert 'train_test_split' in globals(), \\\n",
        "        \"'train_test_split' function not found. Please check your import statement.\"\n",
        "\n",
        "def test_X_train_created():\n",
        "    correct_X_train, _, _, _ = train_test_split(transfusion.drop(columns='target'),\n",
        "                                                transfusion.target,\n",
        "                                                test_size=0.25,\n",
        "                                                random_state=42,\n",
        "                                                stratify=transfusion.target)\n",
        "    assert correct_X_train.equals(X_train), \\\n",
        "        \"'X_train' not created correctly. Did you stratify on the correct column?\"\n",
        "    \n",
        "def test_head_output():\n",
        "    try:\n",
        "        assert \"1750\" in last_output.to_string()\n",
        "    except AttributeError:\n",
        "        assert False, \\\n",
        "            \"Please use X_train.head(2) as the last line of code in the cell to inspect the data, not the display() or print() functions.\"\n",
        "    except AssertionError:\n",
        "        assert False, \\\n",
        "            \"Hmm, the output of the cell is not what we expected. You should see 1750 in the first 2 rows of the X_train DataFrame.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 3, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_train_test_split_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_X_train_created\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_head_output\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 108,
          "data": {
            "text/plain": "3/3 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "45"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "qKtkXEF8-zIR"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. Selecting model using TPOT\n",
        "<p><a href=\"https://github.com/EpistasisLab/tpot\">TPOT</a> is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.</p>\n",
        "<p><img src=\"https://assets.datacamp.com/production/project_646/img/tpot-ml-pipeline.png\" alt=\"TPOT Machine Learning Pipeline\"></p>\n",
        "<p>TPOT will automatically explore hundreds of possible pipelines to find the best one for our dataset. Note, the outcome of this search will be a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">scikit-learn pipeline</a>, meaning it will include any pre-processing steps as well as the model.</p>\n",
        "<p>We are using TPOT to help us zero in on one model that we can then explore and optimize further.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "45"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "ROAdNctF-zIR",
        "outputId": "dca2d9f7-1d38-4872-8dd9-ae4cd26a432c",
        "colab": {
          "referenced_widgets": [
            "3aeea4b6c5af43078401e11ecece2b24"
          ]
        }
      },
      "cell_type": "code",
      "source": [
        "# Import TPOTClassifier and roc_auc_score\n",
        "from tpot import TPOTClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Instantiate TPOTClassifier\n",
        "tpot = TPOTClassifier(\n",
        "    generations=5,\n",
        "    population_size=20,\n",
        "    verbosity=2,\n",
        "    scoring='roc_auc',\n",
        "    random_state=42,\n",
        "    disable_update_check=True,\n",
        "    config_dict='TPOT light'\n",
        ")\n",
        "tpot.fit(X_train, y_train)\n",
        "\n",
        "# AUC score for tpot model\n",
        "tpot_auc_score = roc_auc_score(y_test, tpot.predict_proba(X_test)[:, 1])\n",
        "print(f'\\nAUC score: {tpot_auc_score:.4f}')\n",
        "\n",
        "# Print best pipeline steps\n",
        "print('\\nBest pipeline steps:', end='\\n')\n",
        "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
        "    # Print idx and transform\n",
        "    print(f'{idx}. {transform}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=120.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aeea4b6c5af43078401e11ecece2b24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "Generation 1 - Current best internal CV score: 0.7433977184592779\nGeneration 2 - Current best internal CV score: 0.7433977184592779\nGeneration 3 - Current best internal CV score: 0.7433977184592779\nGeneration 4 - Current best internal CV score: 0.7433977184592779\nGeneration 5 - Current best internal CV score: 0.7433977184592779\n\nBest pipeline: LogisticRegression(input_matrix, C=0.5, dual=False, penalty=l2)\n\nAUC score: 0.7850\n\nBest pipeline steps:\n1. LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "45"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "GRl_4Tru-zIS",
        "outputId": "bf631a57-1d90-4b9f-c18c-26fa4fa135b9"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "def strip_comment_lines(cell_input):\n",
        "    \"\"\"Returns cell input string with comment lines removed.\"\"\"\n",
        "    return '\\n'.join(line for line in cell_input.splitlines() if not line.startswith('#'))\n",
        "\n",
        "last_input = strip_comment_lines(In[-2])\n",
        "\n",
        "def test_TPOTClassifier_loaded():\n",
        "    assert 'TPOTClassifier' in globals(), \\\n",
        "        \"'TPOTClassifier' class not found. Please check your import statement.\"\n",
        "    \n",
        "def test_roc_auc_score_loaded():\n",
        "    assert 'roc_auc_score' in globals(), \\\n",
        "        \"'roc_auc_score' function not found. Please check your import statement.\"\n",
        "\n",
        "def test_TPOTClassifier_instantiated():\n",
        "    assert isinstance(tpot, TPOTClassifier), \\\n",
        "        \"'tpot' is not an instance of TPOTClassifier. Did you assign an instance of TPOTClassifier to 'tpot' variable?\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 3, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_TPOTClassifier_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_roc_auc_score_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_TPOTClassifier_instantiated\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 110,
          "data": {
            "text/plain": "3/3 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "52"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "ZN9tg20Q-zIS"
      },
      "cell_type": "markdown",
      "source": [
        "## 8. Checking the variance\n",
        "<p>TPOT picked <code>LogisticRegression</code> as the best model for our dataset with no pre-processing steps, giving us the AUC score of 0.7850. This is a great starting point. Let's see if we can make it better.</p>\n",
        "<p>One of the assumptions for linear models is that the data and the features we are giving it are related in a linear fashion, or can be measured with a linear distance metric. If a feature in our dataset has a high variance that's orders of magnitude greater than the other features, this could impact the model's ability to learn from other features in the dataset.</p>\n",
        "<p>Correcting for high variance is called normalization. It is one of the possible transformations you do before training a model. Let's check the variance to see if such transformation is needed.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "52"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "hY_P9hE1-zIT",
        "outputId": "7249db41-eca5-47aa-c901-826a6df3f2be"
      },
      "cell_type": "code",
      "source": [
        "# X_train's variance, rounding the output to 3 decimal places\n",
        "\n",
        "X_train.var().round(3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 111,
          "data": {
            "text/plain": "Recency (months)              66.929\nFrequency (times)             33.830\nMonetary (c.c. blood)    2114363.700\nTime (months)                611.147\ndtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "52"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "FYilntcV-zIT",
        "outputId": "3a457e8c-39f7-4f2d-a6fe-0fbced55e61d"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "def strip_comment_lines(cell_input):\n",
        "    \"\"\"Returns cell input string with comment lines removed.\"\"\"\n",
        "    return '\\n'.join(line for line in cell_input.splitlines() if not line.startswith('#'))\n",
        "\n",
        "last_input = strip_comment_lines(In[-2])\n",
        "last_output = _\n",
        "\n",
        "def test_command_syntax():\n",
        "    assert 'X_train' in last_input, \\\n",
        "        \"Did you call 'var()' method on 'X_train' DataFrame?\"\n",
        "    assert 'var' in last_input, \\\n",
        "        \"Did you call 'var()' method?\"\n",
        "    assert 'round(3)' in last_input, \\\n",
        "        \"Did you call 'round()' method with the correct argument?\"\n",
        "    assert last_input.find('var') < last_input.find('round'), \\\n",
        "        \"Did you chain 'var()' and 'round()' methods in the correct order?\"\n",
        "\n",
        "def test_var_output():\n",
        "    try:\n",
        "        assert \"2114363\" in last_output.to_string()\n",
        "    except AttributeError:\n",
        "        assert False, \\\n",
        "            \"Please use X_train.var().round(3) to inspect the variance, not the display() or print() functions.\"\n",
        "    except AssertionError:\n",
        "        assert False, \\\n",
        "            \"Hmm, the output of the cell is not what we expected. You should see 2114363 in your output.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 2, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_command_syntax\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_var_output\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 112,
          "data": {
            "text/plain": "2/2 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "59"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "kIM1Y459-zIU"
      },
      "cell_type": "markdown",
      "source": [
        "## 9. Log normalization\n",
        "<p><code>Monetary (c.c. blood)</code>'s variance is very high in comparison to any other column in the dataset. This means that, unless accounted for, this feature may get more weight by the model (i.e., be seen as more important) than any other feature.</p>\n",
        "<p>One way to correct for high variance is to use log normalization.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "59"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "dbrwaYIe-zIU",
        "outputId": "2982aaa5-a87a-4e65-a611-3e991de09f96"
      },
      "cell_type": "code",
      "source": [
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Copy X_train and X_test into X_train_normed and X_test_normed\n",
        "X_train_normed , X_test_normed = X_train.copy(), X_test.copy()\n",
        "\n",
        "# Specify which column to normalize\n",
        "col_to_normalize = 'Monetary (c.c. blood)'\n",
        "\n",
        "# Log normalization\n",
        "for df_ in [X_train_normed, X_test_normed]:\n",
        "    # Add log normalized column\n",
        "    df_['monetary_log'] = np.log(df_[col_to_normalize])\n",
        "    # Drop the original column\n",
        "    df_.drop(columns=col_to_normalize, inplace=True)\n",
        "\n",
        "# Check the variance for X_train_normed\n",
        "X_train_normed.var().round(3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 113,
          "data": {
            "text/plain": "Recency (months)      66.929\nFrequency (times)     33.830\nTime (months)        611.147\nmonetary_log           0.837\ndtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "59"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "TY8gLFE--zIU",
        "outputId": "32edbf4d-e370-4f3c-b83f-3ee8faee8a15"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "last_output = _\n",
        "\n",
        "def test_numpy_loaded():\n",
        "    assert 'np' in globals(), \\\n",
        "        \"'np' module not found. Please check your import statement.\"\n",
        "\n",
        "def test_X_train_normed_created():\n",
        "    assert 'X_train_normed' in globals(), \\\n",
        "        \"'X_train_normed' DataFrame not found. Please check your variable assignment statement.\"\n",
        "\n",
        "def test_col_to_normalize():\n",
        "    assert col_to_normalize == 'Monetary (c.c. blood)', \\\n",
        "        \"'col_to_normalize' is set to an incorrect column name.\"\n",
        "\n",
        "def test_X_train_normed_log_normalized():\n",
        "    correct_X_train_normed = X_train.copy() \\\n",
        "        .assign(monetary_log = lambda x: np.log(x['Monetary (c.c. blood)'])) \\\n",
        "        .drop(columns='Monetary (c.c. blood)')\n",
        "    assert correct_X_train_normed.equals(X_train_normed), \\\n",
        "        \"'X_train_normed' is incorrect. Are you 'col_to_normalize' in the loop? Did you 'col_to_normalize'?\"\n",
        "\n",
        "def test_var_output():\n",
        "    try:\n",
        "        assert \"611.147\" in last_output.to_string()\n",
        "    except AttributeError:\n",
        "        assert False, \\\n",
        "            \"Please use X_train_normed.var().round(3) as the last line of code in the cell to inspect the variance, not the display() or print() functions.\"\n",
        "    except AssertionError:\n",
        "        assert False, \\\n",
        "            \"Hmm, the output of the cell is not what we expected. You should see 611.147 in your output.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 5, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_numpy_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_X_train_normed_created\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_col_to_normalize\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_X_train_normed_log_normalized\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_var_output\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 114,
          "data": {
            "text/plain": "5/5 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "66"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "4p4_oYFN-zIV"
      },
      "cell_type": "markdown",
      "source": [
        "## 10. Training the logistic regression model\n",
        "<p>The variance looks much better now. Notice that now <code>Time (months)</code> has the largest variance, but it's not the <a href=\"https://en.wikipedia.org/wiki/Order_of_magnitude\">orders of magnitude</a> higher than the rest of the variables, so we'll leave it as is.</p>\n",
        "<p>We are now ready to train the logistic regression model.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "66"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "Cq8AfDtz-zIV",
        "outputId": "ef5b3438-a8d0-4404-f212-3b00525fc98a"
      },
      "cell_type": "code",
      "source": [
        "# Importing modules\n",
        "from sklearn import linear_model\n",
        "\n",
        "# Instantiate LogisticRegression\n",
        "logreg = linear_model.LogisticRegression(\n",
        "    solver='liblinear',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "logreg.fit(X_train_normed, y_train)\n",
        "\n",
        "# AUC score for tpot model\n",
        "logreg_auc_score = roc_auc_score(y_test, logreg.predict_proba(X_test_normed)[:, 1])\n",
        "print(f'\\nAUC score: {logreg_auc_score:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nAUC score: 0.7891\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "66"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "OfibiaQE-zIV",
        "outputId": "05932949-d48f-44ef-924a-78f000b7b747"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "def test_linear_model_loaded():\n",
        "    assert 'linear_model' in globals(), \\\n",
        "        \"'linear_model' module not found. Please check your import statement.\"\n",
        "    \n",
        "def test_roc_auc_score_loaded():\n",
        "    assert 'roc_auc_score' in globals(), \\\n",
        "        \"'roc_auc_score' function not found. Please check your import statement.\"\n",
        "\n",
        "def test_LogisticRegression_instantiated():\n",
        "    assert isinstance(logreg, linear_model.LogisticRegression), \\\n",
        "        (\"'logreg' is not an instance of linear_model.LogisticRegression. \"\n",
        "         \"Did you assign an instance of linear_model.LogisticRegression to 'logreg' variable?\")\n",
        "\n",
        "def test_model_fitted():\n",
        "    assert hasattr(logreg, 'coef_'), \\\n",
        "        \"Did you call 'fit()' method on 'logreg'?\"\n",
        "\n",
        "def test_logreg_auc_score():\n",
        "    assert '{:.4f}'.format(logreg_auc_score) == '0.7891', \\\n",
        "        \"Hmm, the logreg_auc_score is not what we expected. You should see 'AUC score: 0.7891' printed out.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 5, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_linear_model_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_roc_auc_score_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_LogisticRegression_instantiated\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_model_fitted\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_logreg_auc_score\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 116,
          "data": {
            "text/plain": "5/5 tests passed\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "73"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "OlSuZYam-zIW"
      },
      "cell_type": "markdown",
      "source": [
        "## 11. Conclusion\n",
        "<p>The demand for blood fluctuates throughout the year. As one <a href=\"https://www.kjrh.com/news/local-news/red-cross-in-blood-donation-crisis\">prominent</a> example, blood donations slow down during busy holiday seasons. An accurate forecast for the future supply of blood allows for an appropriate action to be taken ahead of time and therefore saving more lives.</p>\n",
        "<p>In this notebook, we explored automatic model selection using TPOT and AUC score we got was 0.7850. This is better than simply choosing <code>0</code> all the time (the target incidence suggests that such a model would have 76% success rate). We then log normalized our training data and improved the AUC score by 0.5%. In the field of machine learning, even small improvements in accuracy can be important, depending on the purpose.</p>\n",
        "<p>Another benefit of using logistic regression model is that it is interpretable. We can analyze how much of the variance in the response variable (<code>target</code>) can be explained by other variables in our dataset.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "73"
        },
        "tags": [
          "sample_code"
        ],
        "trusted": false,
        "id": "XYZF3dac-zIW",
        "outputId": "5daf73bc-a912-4a68-944d-06d4cdd7b2c5"
      },
      "cell_type": "code",
      "source": [
        "# Importing itemgetter\n",
        "from operator import itemgetter\n",
        "\n",
        "# Sort models based on their AUC score from highest to lowest\n",
        "sorted(\n",
        "    [('tpot', tpot_auc_score), ('logreg', logreg_auc_score)],\n",
        "    key=itemgetter(1),\n",
        "    reverse=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 117,
          "data": {
            "text/plain": "[('logreg', 0.7890972663699937), ('tpot', 0.7849650349650349)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "73"
        },
        "tags": [
          "tests"
        ],
        "hide": true,
        "trusted": false,
        "id": "l5Lpt_UP-zIW",
        "outputId": "b1848e09-9123-462f-856d-7bddb8a2d4f6"
      },
      "cell_type": "code",
      "source": [
        "%%nose\n",
        "\n",
        "last_output = _\n",
        "\n",
        "def test_itemgetter_loaded():\n",
        "    assert 'itemgetter' in globals(), \\\n",
        "        \"'itemgetter' function not found. Please check your import statement.\"\n",
        "\n",
        "def test_logreg_is_first_in_the_list():\n",
        "    assert last_output[0][0] == 'logreg', \\\n",
        "        \"Expected 'logreg' to be first in the list.\"\n",
        "\n",
        "def test_logreg_score():\n",
        "    assert round(last_output[0][1], 4) == 0.7891, \\\n",
        "        \"Hmm, the output of the cell is not what we expected. You should see 0.7851 as 'logreg' score in your output.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/json": "{\"success\": true, \"summary\": {\"tests\": 3, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_itemgetter_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_logreg_is_first_in_the_list\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_logreg_score\", \"success\": true, \"message\": \"\"}]}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 118,
          "data": {
            "text/plain": "3/3 tests passed\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}